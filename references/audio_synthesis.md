# Audio Synthesis

## Surveys

- Zhang, Chenshuang, Chaoning Zhang, Sheng Zheng, Mengchun Zhang, Maryam Qamar, Sung-Ho Bae, and In So Kweon. ["A survey on audio diffusion models: Text to speech synthesis and enhancement in generative ai."](https://arxiv.org/pdf/2303.13336.pdf), 2023.



## Diffusion-based Models

- **Stable Audio**: Evans, Zach, C. J. Carr, Josiah Taylor, Scott H. Hawley, and Jordi Pons. ["Fast Timing-Conditioned Latent Audio Diffusion."]( https://arxiv.org/pdf/2402.04825.pdf), 2024.

- **MusicGen**: Copet, Jade, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre DÃ©fossez. ["Simple and Controllable Music Generation."](https://arxiv.org/pdf/2306.05284.pdf), 2023.

- **AudioLDM 2** : Liu, Haohe, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, and Mark D. Plumbley. ["AudioLDM 2: Learning holistic audio generation with self-supervised pretraining."](https://arxiv.org/pdf/2308.05734.pdf), 2023.

- **AudioLDM**: Liu, Haohe, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark D. Plumbley. ["AudioLDM Text-to-audio generation with latent diffusion models."](https://audioldm.github.io/), 2023.

- **Make-an-audio**: Huang, Rongjie, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao. ["Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models."](https://text-to-audio.github.io/), 2023.

- **Diffwave**: Kong, Zhifeng, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. ["Diffwave: A versatile diffusion model for audio synthesis."](https://arxiv.org/pdf/2009.09761.pdf), 2020.


## VAE-based Models

- "Jukebox: A Generative Model for Music", https://arxiv.org/pdf/2005.00341.pdf
